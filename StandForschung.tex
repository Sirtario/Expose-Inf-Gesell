\chapter{Stand der Forschung}

Nachfolgend wird der Stand der Forschung zum Thema Möglichkeiten zur Verhinderung des Missbrauchs bildergenerierender \GLSabrev{ai}s zur Erzeugung ethisch fragwürdiger Inhalte mit Fokus darauf beleuchtet, wie in der Praxis verhindert wird, dass \GLSabrev{igai} zur Erzeugung ethisch fragwürdiger Inhalte missbraucht werden.
\\\\
Salminen et al. zeigen, dass AI nicht ethisch ist, sondern Ergebnisse auf Basis ihres Datensatzes liefert, sodass Bias schnell zu diskriminierenden Verteilungen von Ergebnismengen führen können \cite{Salminen}. Jobin et al. und  Partadiredja et al. legen bereits vorhandene Richtlinien und ähnliche Werke zu ethischen Festlegungen bezüglich AI dar \cite{Jobin} \cite{Partadiredja}, wobei Partadiredja et al. auch Unterschiede zwischen von AI und Menschen generiertem Mediacontent einschließlich Bildern herausarbeiten und dabei insbesondere auf ethische Implikationen eingehen \cite{Partadiredja}.
\\\\
Es gibt solche weisenden, jedoch nicht gesetzlich bindenden Vorschriften also, jedoch demonstrieren Ayling und Chapman, dass diese bei der Entwicklung und dem Einsatz von \GLSabrev{ai} noch nicht ausreichend praktische Anwendung finden \cite{Ayling}. Hierzu werden explizit Defizite aktueller Werkzeuge für Audits und Risikobewertungen bezüglich ethischer Rahmenwerke und Grundsätze in der \GLSabrev{ai} aufgezeigt, die in Zukunft berücksichtigt werden sollten \cite{Ayling}. Prinzipiell gibt es bereits Werke, deren Ergebnisse die Umsetzung verschiedener Richtlinien fördern können, z. B. durch eine Definition von Anforderungen an \GLSabrev{ai} in der EU \cite{EUCommision}. 
\\\\
Des weiteren zeigen Jobin et al. und Hagendorff Strategien für die Implementierung von Richtlinien für ethische Prinzipien für \GLSabrev{ai} auf \cite{Jobin} \cite{Hagendorff}. Stahl et al. diskutieren Ethik von \GLSabrev{ai} und Robotik und liefert Einblicke, wie ethische Prinzipien im Allgemeinen in der Praxis angewendet werden können \cite{Stahl}. Eine Zusammenstellung von \Gls{bias} in verschiedenen Phasen des \GLSabrev{ai}-Prozesses und Empfehlungen für bewährte Verfahren und Richtlinien zur Identifizierung und Minderung von Verzerrungen in \GLSabrev{ai}-Systemen für Entwickler von maschinellem Lernen geben Srinivasan und Chander \cite{Srinivasan}. Jameel et al. gehen auf Grundlage einer Vorstellung verschiedener \GLSabrev{ai}-Modelle auf bestimmte ethische Probleme ein und zeigt Wege auf, Daten von ethisch hoher Qualität zu erhalten \cite{Jameel}. Zudem geben einige Unternehmen Überblick über ihre Ansätze zur Verminderung von Verzerrungen bei der Benutzung von \GLSabrev{ai}, beispielsweise IBM mithilfe eine auf Prozessen basierende Darlegung, wie ethisch korrekt mit \GLSabrev{ai} umgegangen werden kann \cite{Hobson}.
\\\\
Eine Variante, bestimmte Inhalte zu blockieren, besteht in der Filterung. Einen solche Filter für Bilder beschreiben Zheng et al. \cite{Zheng}. Die beschriebene Software kann Haut auf Bildern erkennen und darüber z. B. nicht jugendfreie Inhalte und gesetzlich verbotene Symbole herausfiltern. 
\\\\
Zusammenfassend lässt sich also sagen, dass die Problematik bei der Umsetzung ethischer Prinzipien in der \GLSabrev{ai} erkannt und durch Richtlinien u. ä. Anleitungen gegeben werden, wie diese geschehen kann. Außerdem gibt es Untersuchungen zur Anforderungsanalyse und Vorschläge zur Implementierung für diese Umsetzung, allerdings keinen zusammenfassenden Überblick, was denn tatsächlich praktisch getan wird, um Missbrauch bildergenerierender \GLSabrev{ai}s zur Erzeugung ethisch fragwürdiger Inhalte zu verhindern. \\
\newpage 
Die betrachteten Arbeiten lassen sich somit wie folgt inhaltlich gruppieren: Es gibt wissenschaftliche Arbeiten zur Analyse und Filterung bestimmter Inputs/Outputs wie Haut und Symbole aus Bildern \cite{Zheng} oder unmoralische Wörter oder Phrasen \cite{Shah}. Des weiteren werden Richtlinien zum ethischen Einsatz von \GLSabrev{ai} zusammenstellt oder definiert und diskutiert \cite{Ayling} \cite{Srinivasan} \cite{Jameel} \cite{Hagendorff} \cite{Jobin} \cite{Unity} \cite{EUCommision} \cite{Mueller}. Neben diesen Richtlinien werden Frameworks für \GLSabrev{ai} entwickelt \cite{Huang} \cite{Mueller}. Es werden Probleme von \GLSabrev{ai}s ermittelt \cite{Ayling}, beispielsweise Bias \cite{Salminen} \cite{Jameel}, Kopien \cite{Somepalli}, wobei u. a. Bias auch zu ethisch fragwürdigen Resultaten führen kann \cite{Zuber}. Lösungsansätze für diese Probleme werden allgemein für \GLSabrev{ai}-spezifische Probleme ohne Konzentration auf ein bestimmtes \cite{Ayling} \cite{Avelar}, aber auch konkret für bestimmte Problemkategorien wie Bias \cite{Srinivasan} \cite{Jameel} untersucht. Technikfolgen und Regulierungsfragen für verschiedene von \GLSabrev{ai} beeinflusste Kontexte wie Politik und Wirtschaft werden analysiert \cite{Pawelec}.