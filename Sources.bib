@book{Avelar,
  author         = {Avelar, P. et al.},
  publisher      = {Springer-Verlag, Berlin, Heidelberg.},
  title          = {Measuring Ethics in AI with AI: A Methodology and Dataset Construction},
  year           = {2022}
}
@article{Ayling,
  author          = {J. Ayling and A. Chapman},
  journal         = {AI and Ethics},
  number          = {2},
  title           = {Putting AI ethics to work: are the tools fit for purpose?},
  volume          = {2021-2},
  year            = {2021}
}
@article{Bostrom,
  author          = {Bostrom, Nick, Eliezer Yudowsky},
  journal         = {In Artificial intelligence safety and security},
  number          = {-},
  title           = {The ethics of artificial intelligence.},
  volume          = {-},
  year            = {2018}
}
@article{EUCommision,
  author          = {European Commission},
  journal         = {-},
  number          = {-},
  title           = {Ethics guidelines for trustworthy AI},
  volume          = {-},
  year            = {2019}
}
@article{Hagendorff,
  author          = {Hagendorff, T},
  journal         = {Minds an Machines},
  number          = {1},
  title           = {The Ethics of AI Ethics: An Evaluation of Guidelines.},
  volume          = {30},
  year            = {2020}
}
@misc{hagerty2019global,
      title={Global AI Ethics: A Review of the Social Impacts and Ethical Implications of Artificial Intelligence}, 
      author={Alexa Hagerty and Igor Rubinov},
      year={2019},
      eprint={1907.07892},
      archivePrefix={arXiv},
      primaryClass={cs.CY}
}
@article{Hobson,
  author          = {S. Hobson und A. Dortch},
  journal         = {IBM Policy Lab},
  number          = {-},
  title           = {Mitigating Bias in Artificial Intelligence},
  volume          = {-},
  year            = {2021}
}
@article{Jameel,
  author          = {Jameel, T et al.},
  journal         = {iCoMET 2020},
  number          = {1-6},
  title           = {Ethics of Artificial Intelligence : Research Challenges and Potential Solutions},
  volume          = {-},
  year            = {2020}
}
@article{Pawelec,
  author          = {M. Pawelec und C. Beiß},
  journal         = {-},
  number          = {-},
  title           = {Deepfakes. Technikfolgen und Regulierungsfragen aus ethischer und sozialwissenschaftlicher Perspektive},
  volume          = {-},
  year            = {2021}
}
@article{Salminen,
  author          = {Salminen, J et al.},
  journal         = {CHI Conference on Human Factors in Computing Systems},
  number          = {-},
  title           = {Analyzing Demographic Bias in Artificially Generated Facial Pictures},
  volume          = {20},
  year            = {2020}
}
@article{Shah,
  author          = {Shah. F et al.},
  journal         = {-},
  number          = {-},
  title           = {Artificial Intelligence as a Service for Immoral ContentDetection and Eradication},
  volume          = {-},
  year            = {2022}
}
@article{Somepalli,
  author          = {Somepalli, G et al.},
  journal         = {ArXiv},
  number          = {2212.03860},
  title           = {Diffusion Art or Digital Forgery? Investigating Data Replication in Diffusion Models},
  volume          = {-},
  year            = {2022}
}
@article{Stahl,
  author          = { B. C. Stahl, D. Schroeder \& R. Rodrigues R},
  journal         = {Springerbriefs in research and innovation governance},
  number          = {-},
  title           = {The ethics of artificial intelligence: A conclusion},
  volume          = {-},
  year            = {2023}
}
@article{Sun,
  author          = {Sun, F., Ye, R},
  journal         = {Ethics of Artificial Intelligence},
  number          = {-},
  title           = {Moral Considerations of Artificial Intelligence},
  volume          = {-},
  year            = {2023}
}
@article{Srinivasan,
author = {Srinivasan, Ramya and Chander, Ajay},
title = {Biases in AI Systems: A Survey for Practitioners},
year = {2021},
issue_date = {March-April 2021},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {2},
issn = {1542-7730},
url = {https://doi.org/10.1145/3466132.3466134},
doi = {10.1145/3466132.3466134},
abstract = {This article provides an organization of various kinds of biases that can occur in the AI pipeline starting from dataset creation and problem formulation to data analysis and evaluation. It highlights the challenges associated with the design of bias-mitigation strategies, and it outlines some best practices suggested by researchers. Finally, a set of guidelines is presented that could aid ML developers in identifying potential sources of bias, as well as avoiding the introduction of unwanted biases. The work is meant to serve as an educational resource for ML developers in handling and addressing issues related to bias in AI systems.},
journal = {Queue},
month = {may},
pages = {45–64},
numpages = {20}
}

@article{Jobin,
	abstract = {In the past five years, private companies, research institutions and public sector organizations have issued principles and guidelines for ethical artificial intelligence (AI). However, despite an apparent agreement that AI should be `ethical', there is debate about both what constitutes `ethical AI'and which ethical requirements, technical standards and best practices are needed for its realization. To investigate whether a global agreement on these questions is emerging, we mapped and analysed the current corpus of principles and guidelines on ethical AI. Our results reveal a global convergence emerging around five ethical principles (transparency, justice and fairness, non-maleficence, responsibility and privacy), with substantive divergence in relation to how these principles are interpreted, why they are deemed important, what issue, domain or actors they pertain to, and how they should be implemented. Our findings highlight the importance of integrating guideline-development efforts with substantive ethical analysis and adequate implementation strategies.},
	author = {Jobin, Anna and Ienca, Marcello and Vayena, Effy},
	date = {2019/09/01},
	date-added = {2023-04-30 12:14:29 +0200},
	date-modified = {2023-04-30 12:14:29 +0200},
	doi = {10.1038/s42256-019-0088-2},
	id = {Jobin2019},
	isbn = {2522-5839},
	journal = {Nature Machine Intelligence},
	number = {9},
	pages = {389--399},
	title = {The global landscape of AI ethics guidelines},
	url = {https://doi.org/10.1038/s42256-019-0088-2},
	volume = {1},
	year = {2019},
	bdsk-url-1 = {https://doi.org/10.1038/s42256-019-0088-2}
}

@InCollection{Mueller,
	author       =	{Müller, Vincent C.},
	title        =	{{Ethics of Artificial Intelligence and Robotics}},
	booktitle    =	{The {Stanford} Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	howpublished =	{\url{https://plato.stanford.edu/archives/sum2021/entries/ethics-ai/}},
	year         =	{2021},
	edition      =	{{S}ummer 2021},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}

@INPROCEEDINGS{Partadiredja,
  author={Partadiredja, Reza Arkan and Serrano, Carlos Entrena and Ljubenkov, Davor},
  booktitle={2020 13th CMI Conference on Cybersecurity and Privacy (CMI) - Digital Transformation - Potentials and Challenges(51275)}, 
  title={AI or Human: The Socio-ethical Implications of AI-Generated Media Content}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  doi={10.1109/CMI51275.2020.9322673}}

@INPROCEEDINGS{Zheng,
  author={Huicheng Zheng and Hongmei Liu and Daoudi, M.},
  booktitle={2004 IEEE International Conference on Multimedia and Expo (ICME) (IEEE Cat. No.04TH8763)}, 
  title={Blocking objectionable images: adult images and harmful symbols}, 
  year={2004},
  volume={2},
  number={},
  pages={1223-1226 Vol.2},
  doi={10.1109/ICME.2004.1394442}}
@misc{Heikkilae,
  author       = {Melissa Heikkilä},
  howpublished = {\url={https://www.technologyreview.com/2023/02/24/1069093/ai-image-generator-midjourney-blocks-porn-by-banning-words-about-the-human-reproductive-system/},},
  title        = {AI image generator Midjourney blocks porn by banning words about the human reproductive system},
  year         = {2023},
  note={Accessed: 30.04.2023}
}
@misc{NelsonMidjourney,
  author       = {Jason Nelson},
  howpublished = {\url={https://decrypt.co/124972/midjourney-free-ai-image-generation-stopped-over-deepfakes},},
  title        = {Midjourney Kills Free AI Image Generator Access After Explosion of Deep Fakes},
  year         = {2023},
  note={Accessed: 30.04.2023}
}
@misc{Hadero,
  author       = {Haleluya Hadero},
  howpublished = {\url={https://apnews.com/article/deepfake-porn-celebrities-dalle-stable-diffusion-midjourney-ai-e7935e9922cda82fbcfb1e1a88d9443a},},
  title        = {Deepfake porn could be a growing problem amid AI race},
  year         = {2023},
  note={Accessed: 30.04.2023}
}
@misc{Schmidt,
  author       = {Lia P. Schmidt},
  howpublished = {\url={https://www.linkedin.com/pulse/racial-gender-bias-lessons-learned-from-midjourney-lia/},},
  title        = {Racial and Gender Bias Lessons Learned from Midjourney and Disordered },
  year         = {2023},
  note={Accessed: 30.04.2023}
}
@misc{Garcia,
  author       = { Chris Garcia },
  howpublished = {\url={https://computerhistory.org/blog/harold-cohen-and-aaron-a-40-year-collaboration/},},
  title        = {HAROLD COHEN AND AARON—A 40-YEAR COLLABORATION},
  year         = {2016},
  note={Accessed: 30.04.2023}
}
@misc{Unity,
  author       = { Unity Technologies },
  howpublished = {\url={https://blog.unity.com/engine-platform/introducing-unitys-guiding-principles-for-ethical-ai},},
  title        = {Introducing Unity’s Guiding Principles for Ethical AI},
  year         = {2016},
  note={Accessed: 30.04.2023}
}

@article{Minkkinen,
	abstract = {Artificial intelligence (AI), which refers to both a research field and a set of technologies, is rapidly growing and has already spread to application areas ranging from policing to healthcare and transport. The increasing AI capabilities bring novel risks and potential harms to individuals and societies, which auditing of AI seeks to address. However, traditional periodic or cyclical auditing is challenged by the learning and adaptive nature of AI systems. Meanwhile, continuous auditing (CA) has been discussed since the 1980s but has not been explicitly connected to auditing of AI. In this paper, we connect the research on auditing of AI and CA to introduce CA of AI (CAAI). We define CAAI as a (nearly) real-time electronic support system for auditors that continuously and automatically audits an AI system to assess its consistency with relevant norms and standards. We adopt a bottom-up approach and investigate the CAAI tools and methods found in the academic and grey literature. The suitability of tools and methods for CA is assessed based on criteria derived from CA definitions. Our study findings indicate that few existing frameworks are directly suitable for CAAI and that many have limited scope within a particular sector or problem area. Hence, further work on CAAI frameworks is needed, and researchers can draw lessons from existing CA frameworks; however, this requires consideration of the scope of CAAI, the human--machine division of labour, and the emerging institutional landscape in AI governance. Our work also lays the foundation for continued research and practical applications within the field of CAAI.},
	author = {Minkkinen, Matti and Laine, Joakim and M{\"a}ntym{\"a}ki, Matti},
	date = {2022/10/04},
	date-added = {2023-04-30 22:19:44 +0200},
	date-modified = {2023-04-30 22:19:44 +0200},
	doi = {10.1007/s44206-022-00022-2},
	id = {Minkkinen2022},
	isbn = {2731-4669},
	journal = {Digital Society},
	number = {3},
	pages = {21},
	title = {Continuous Auditing of Artificial Intelligence: a Conceptualization and Assessment of Tools and Frameworks},
	url = {https://doi.org/10.1007/s44206-022-00022-2},
	volume = {1},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1007/s44206-022-00022-2}
  }
  @misc{gebru2021datasheets,
      title={Datasheets for Datasets}, 
      author={Timnit Gebru and Jamie Morgenstern and Briana Vecchione and Jennifer Wortman Vaughan and Hanna Wallach and Hal Daumé III au2 and Kate Crawford},
      year={2021},
      eprint={1803.09010},
      archivePrefix={arXiv},
      primaryClass={cs.DB}
}

@article{Mittelstadt,
	abstract = { In information societies, operations, decisions and choices previously left to humans are increasingly delegated to algorithms, which may advise, if not decide, about how data should be interpreted and what actions should be taken as a result. More and more often, algorithms mediate social processes, business transactions, governmental decisions, and how we perceive, understand, and interact among ourselves and with the environment. Gaps between the design and operation of algorithms and our understanding of their ethical implications can have severe consequences affecting individuals as well as groups and whole societies. This paper makes three contributions to clarify the ethical importance of algorithmic mediation. It provides a prescriptive map to organise the debate. It reviews the current discussion of ethical aspects of algorithms. And it assesses the available literature in order to identify areas requiring further work to develop the ethics of algorithms. },
	author = {Brent Daniel Mittelstadt and Patrick Allo and Mariarosaria Taddeo and Sandra Wachter and Luciano Floridi},
	doi = {10.1177/2053951716679679},
	eprint = {https://doi.org/10.1177/2053951716679679},
	journal = {Big Data \& Society},
	number = {2},
	pages = {2053951716679679},
	title = {The ethics of algorithms: Mapping the debate},
	url = {https://doi.org/10.1177/2053951716679679},
	volume = {3},
	year = {2016},
	bdsk-url-1 = {https://doi.org/10.1177/2053951716679679}}


@article{WILSON2022101652,
	abstract = {Calls for public engagement and participation in AI governance align strongly with a public value management approach to public administration. Simultaneously, the prominence of commercial vendors and consultants in AI discourse emphasizes market value and efficiency in a way often associated with the private sector and New Public Management. To understand how this might influence the consolidation of AI governance regimes and decision-making by public administrators, 16 national strategies for AI are subjected to content analysis. References to the public's role and public engagement mechanisms are mapped across national strategies, as is the articulation of values related to professionalism, efficiency, service, engagement, and the private sector. Though engagement rhetoric is common, references to specific engagement mechanisms and activities are rare. Analysis of value relationships highlights congruence of engagement values with professionalism and private sector values, and raises concerns about neoliberal technology frames that normalize AI, obscuring policy complexity and trade-offs.},
	author = {Christopher Wilson},
	doi = {https://doi.org/10.1016/j.giq.2021.101652},
	issn = {0740-624X},
	journal = {Government Information Quarterly},
	keywords = {Public engagement, Public values, Public value management, Artificial intelligence, Technology frames, Technology policy, Participation, Open government},
	number = {1},
	pages = {101652},
	title = {Public engagement and AI: A values analysis of national strategies},
	url = {https://www.sciencedirect.com/science/article/pii/S0740624X21000885},
	volume = {39},
	year = {2022},
	bdsk-url-1 = {https://www.sciencedirect.com/science/article/pii/S0740624X21000885},
	bdsk-url-2 = {https://doi.org/10.1016/j.giq.2021.101652}}
@inproceedings{Zytko,
author = {Zytko, Douglas and J. Wisniewski, Pamela and Guha, Shion and P. S. Baumer, Eric and Lee, Min Kyung},
title = {Participatory Design of AI Systems: Opportunities and Challenges Across Diverse Users, Relationships, and Application Domains},
year = {2022},
isbn = {9781450391566},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3491101.3516506},
doi = {10.1145/3491101.3516506},
abstract = {Participatory design (PD) for Artificially Intelligent (AI) systems has gained in popularity in recent years across multiple application domains, both within the private and public sectors. PD methods broadly enable stakeholders of diverse backgrounds to inform new use cases for AI and the design of AI-based technologies that directly impact people's lives. Such participation can be vital for mitigating adverse implications of AI on society that are becoming increasingly apparent and pursuing more positive impact, especially to vulnerable populations. This panel brings together researchers who have, or are, conducting participatory design of AI systems across diverse subject areas. The goal of the panel is to elucidate similarities and differences, as well as successes and challenges, in how PD methods can be applied to Artificially Intelligent systems in practical and meaningful ways. The panel serves as an opportunity for the HCI research community to collectively reflect on opportunities for PD of AI to facilitate collaboration amongst stakeholders, as well as persistent challenges to participatory AI design.},
booktitle = {Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
articleno = {154},
numpages = {4},
keywords = {diversity, Participatory design, artificial intelligence, AI, PD},
location = {New Orleans, LA, USA},
series = {CHI EA '22}
}

@article{Vogel,
	abstract = {Abstract Cross-sector partnerships (CSPs) addressing economic, social, and environmental issues continue to be a vibrant topic in management research and beyond. However, compared to the exogenous factors that drive collaborative advantage through structures and governance, the endogenous problems of collaborating across different institutional logics, residing at the micro-level of interactions among partners from the business, government, and nonprofit sectors, have received scant attention. The preoccupation with success factors often leads to a bias toward the problem-solving capacities of CSPs at the neglect of the considerable barriers to successful collaboration across sectors. This study addresses this shortcoming and extracts an institutional approach of CSPs from an integrative review of the literature combining bibliometric methods with qualitative reviewing. A bibliometric map shows how the literature is divided into several clusters, each addressing a specific type of CSP but not engaging much in exchange with other clusters. Zooming in on the clusters provides a more nuanced picture of how institutional theory has hitherto been applied to CSPs. We build on these pieces of the puzzle and assemble them into a preliminary framework that accounts for inter-institutional conflicts in CSPs and actor-level responses to these conflicts. Our framework introduces a new analytical platform that facilitates multi-level research, bringing the micro-level of individual actors back in and connecting it with institutional frames at the macro-level.},
	author = {Vogel, Rick and G{\"o}bel, Markus and Grewe-Salfeld, Marit and Herbert, Barbara and Matsuo, Yuka and Weber, Christiana},
	doi = {https://doi.org/10.1111/ijmr.12283},
	eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/ijmr.12283},
	journal = {International Journal of Management Reviews},
	number = {3},
	pages = {394-414},
	title = {Cross-sector partnerships: Mapping the field and advancing an institutional approach},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ijmr.12283},
	volume = {24},
	year = {2022},
	bdsk-url-1 = {https://onlinelibrary.wiley.com/doi/abs/10.1111/ijmr.12283},
	bdsk-url-2 = {https://doi.org/10.1111/ijmr.12283}}

@article{Roberto,
  abstract = {During the last two years there has been a plethora of largegenerative models such as ChatGPT or Stable Diffusion that have beenpublished.  Concretely,  these  models  are  able  to  perform  tasks  such  asbeing a general question and answering system or automatically creat-ing artistic images that are revolutionizing several sectors. Consequently,the implications that these generative models have in the industry andsociety are enormous, as several job positions may be transformed. Forexample,  Generative  AI  is  capable  of  transforming  effectively  and  cre-atively  texts  to  images,  like  the  DALLE-2  model;  text  to  3D  images,like  the  Dreamfusion  model;  images  to  text,  like  the  Flamingo  model;texts to video, like the Phenaki model; texts to audio, like the AudioLMmodel; texts to other texts, like ChatGPT; texts to code, like the Codexmodel; texts to scientific texts, like the Galactica model or even createalgorithms like AlphaTensor. This  work consists on  an attempt to de-scribe in a concise way the main models are sectors that are affected bygenerative AI and to provide a taxonomy of the main generative modelspublished recently.},
  author = {Roberto Gozalo-Brizuela, Eduardo C. Garrido-Merchan},
  doi = {https://doi.org/10.48550/arXiv.2301.04655},
  pages = {22},
  title = {ChatGPT is not all you need. A State of the Art Review of large Generative AI models},
  year = {2023}
}

@misc{Serafeim,
  author = {Serafeim Loukas},
  howpublished = {\url={https://towardsdatascience.com/what-is-machine-learning-a-short-note-on-supervised-unsupervised-semi-supervised-and-aed1573ae9bb},},
  title = {What is Machine Learning: Supervised, Unsupervised, Semi-Supervised and Reinforcement learning methods},
  year = {2020},
  note={Accessed: 20.05.2023}
}

@article{Shorten,
author = {Shorten, Connor and Khoshgoftaar, Taghi and Furht, Borko},
year = {2021},
month = {07},
pages = {},
title = {Text Data Augmentation for Deep Learning},
volume = {8},
journal = {Journal of Big Data},
doi = {10.1186/s40537-021-00492-0}
}

@article{Kurakin,
author = {Kurakin, Alexey and Goodfellow, Ian and Bengio, Samy},
year = {2016},
month = {11},
pages = {},
title = {Adversarial Machine Learning at Scale}
}

@misc{Jang,
  title={How DALL-E Credits Work},
  author={Joanne Jang},
  year={2023},
  howpublished={\url{https://help.openai.com/en/articles/6399305-how-dall-e-credits-work}},
  note={Accessed: 20.05.2023}
}

@article{UNESCO,
	author          = {UNESCO [66265]},
	journal         = {UNESCO 41st General Conference},
	number          = {SHS/BIO/PI/2021/1},
	title           = {Recommendation on the Ethics of Artificial Intelligence},
	year            = {2022},
	url = {https://unesdoc.unesco.org/ark:/48223/pf0000381137?posInSet=9&queryId=3e417372-b912-4747-86d0-db91cd40087a}
}

@article{Deutscher_Bundestag,
  author          = {Deutscher Bundestag},
	journal         = {-},
	number          = {Drucksache 20/4413},
	title           = {Antwort der Bundesregierung auf die Kleine Anfrage der Abgeordneten Barbara Lenk, Joana Cotar,Eugen Schmidt, Beatrix von Storch und der Fraktion der AfD –Drucksache 20/4175–},
  year            = {2022},
  url = {https://dserver.bundestag.de/btd/20/044/2004413.pdf}
}

@misc{GesetzesentwurfEUComm,
	author          = {European Commission},
	journal         = {},
	number          = {2021/0106(COD)},
	title           = {ERORDNUNG DES EUROPÄISCHEN PARLAMENTS UND DES RATES ZUR FESTLEGUNG HARMONISIERTER VORSCHRIFTEN FÜR KÜNSTLICHE INTELLIGENZ (GESETZ ÜBER KÜNSTLICHE INTELLIGENZ) UND ZUR ÄNDERUNG BESTIMMTER RECHTSAKTE DER UNION},
	year            = {2022},
  month           = {04},
	url = {https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX%3A52021PC0206}
}